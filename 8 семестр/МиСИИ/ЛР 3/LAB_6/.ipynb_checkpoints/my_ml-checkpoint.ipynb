{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3281066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AI\\Project7_ML\\machinelearningpytorch\\machinelearning\\autograder.py:282: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  assert all([(expected is '?' or actual == expected) for (actual, expected) in zip(node.detach().numpy().shape, expected_shape)]), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question q1\n",
      "===========\n",
      "*** q1) check_perceptron\n",
      "Sanity checking perceptron...\n",
      "Sanity checking perceptron weight updates...\n",
      "NumEpoch= 1\n",
      "NumEpoch= 1\n",
      "NumEpoch= 2\n",
      "NumEpoch= 2\n",
      "Sanity checking complete. Now training perceptron\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumEpoch= 13\n",
      "*** PASS: check_perceptron\n",
      "\n",
      "### Question q1: 6/6 ###\n",
      "\n",
      "Finished at 10:33:35\n",
      "\n",
      "Provisional grades\n",
      "==================\n",
      "Question q1: 6/6\n",
      "------------------\n",
      "Total: 6/6\n",
      "\n",
      "Your grades are NOT yet registered.  To register your grades, make sure\n",
      "to follow your instructor's guidelines to receive credit on your project.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run autograder.py -q q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b402377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question q2\n",
      "===========\n",
      "*** q2) check_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AI\\Project7_ML\\machinelearningpytorch\\machinelearning\\autograder.py:282: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  assert all([(expected is '?' or actual == expected) for (actual, expected) in zip(node.detach().numpy().shape, expected_shape)]), (\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= tensor(0.9937, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6576, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9749, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6284, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8041, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7795, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8472, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6544, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8523, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8057, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6362, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6399, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6462, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6035, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5054, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7214, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5967, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6850, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4924, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4568, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6437, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5585, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5472, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7098, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6287, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6704, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4570, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6530, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3898, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4465, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4001, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7237, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.4429, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4794, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5972, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.2958, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7195, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5842, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8164, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5067, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6729, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4611, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4850, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4150, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7185, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5996, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6246, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5940, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5210, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9015, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7588, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4475, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4556, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5620, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4638, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5775, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6383, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4998, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5908, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5978, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5731, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6283, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7667, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6081, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5903, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5566, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5508, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5899, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9275, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6370, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6335, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7939, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8394, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4551, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6778, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7202, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8866, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7693, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7982, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6688, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.9660, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5266, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6658, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0112, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9495, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6710, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7587, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7627, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.9119, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8782, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9316, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9865, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5831, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7772, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6784, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6758, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6895, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6178, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7015, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7296, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8805, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8803, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8118, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5800, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5032, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7591, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7923, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7672, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5225, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4902, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5796, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5437, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5371, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4129, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4763, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4286, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4630, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5775, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3543, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6600, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.4829, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3097, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5800, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4002, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4276, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3630, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4462, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4348, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.3939, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4687, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3717, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3992, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4578, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4562, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6019, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3456, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5608, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5853, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6606, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5077, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5259, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4168, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5830, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5465, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5229, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6741, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8414, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7721, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6944, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6137, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7811, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8726, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7478, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8800, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8546, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8967, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8604, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0761, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9143, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9316, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8566, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8197, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0300, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2273, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2385, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1754, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6427, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0880, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= tensor(1.0145, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1804, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9246, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7404, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0638, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7732, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1469, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3159, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7953, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1801, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9643, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9949, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6938, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0177, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8118, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8978, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.2421, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7807, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6920, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7948, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7608, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8713, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5158, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5611, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8458, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4927, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7440, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5650, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5327, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7748, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4913, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5257, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6047, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3863, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5797, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5289, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5683, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4401, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6221, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4396, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.3554, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4567, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4552, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6373, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5821, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5630, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3770, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5058, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.4088, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5308, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3270, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5565, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7349, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5634, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6801, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7154, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5310, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6023, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4990, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8791, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7786, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6188, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8534, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5783, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7137, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6746, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7065, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6226, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6951, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1980, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9266, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9675, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.4647, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9962, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1093, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8522, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1146, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9492, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8294, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0286, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1034, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8887, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9436, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0849, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0212, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6525, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0558, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1557, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7366, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0748, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0194, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0026, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2253, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8792, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9216, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0244, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6443, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0479, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0707, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9136, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2554, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6962, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0537, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1176, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.0418, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8921, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1210, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7994, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5929, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0136, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8396, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2039, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6810, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1403, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8903, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1585, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6735, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8036, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6971, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1192, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1237, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9028, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1852, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1999, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5930, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7859, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5819, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7888, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7262, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2132, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0206, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9897, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1699, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6866, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5506, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8735, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7564, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9537, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0787, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0774, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8051, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0126, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0256, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8037, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7785, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1695, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0085, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7575, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3627, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8857, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9420, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9196, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.3699, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1281, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1787, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2178, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9578, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7428, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7227, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8674, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6520, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3084, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0616, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1616, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5995, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0681, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6461, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0595, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1725, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7900, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9687, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9492, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0259, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7152, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7911, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9583, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8525, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1090, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= tensor(0.8199, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7921, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9800, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8641, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4612, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9907, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8117, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3990, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9603, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6622, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9463, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5602, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1002, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7640, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1149, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4819, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6704, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8222, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7526, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7156, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8177, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1782, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5541, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2352, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9191, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9502, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5858, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5294, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5017, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7860, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.0011, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0427, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0733, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4728, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4295, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8768, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7343, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6300, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7476, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5689, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2153, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2299, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6161, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9065, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6514, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0199, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1873, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0349, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3485, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0297, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9477, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8133, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9555, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7335, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.0900, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8736, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5246, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4986, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2360, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9449, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2496, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9546, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1553, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6111, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3550, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0815, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2728, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0436, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8323, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3944, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.9067, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2851, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7654, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1794, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6667, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5544, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3294, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2700, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1364, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9958, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5378, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7509, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4230, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0636, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5660, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3520, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.6846, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0554, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8584, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7690, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5673, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7429, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7901, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5287, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.5517, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9390, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6652, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8481, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4015, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5499, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6989, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2415, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.9256, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0352, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8993, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2798, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3005, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3888, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9626, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4369, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.4453, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6985, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1710, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4936, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9570, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2667, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5545, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4383, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8622, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4043, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0848, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2680, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9450, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9940, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7577, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1586, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.9391, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2136, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6295, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5563, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1634, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0233, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1329, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1411, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.9728, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7610, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8936, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1384, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7726, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6241, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5429, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7205, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.4978, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7113, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9411, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8177, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7236, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5504, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6288, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5076, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6553, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9114, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6972, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3804, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5635, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7038, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3244, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6700, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8943, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4624, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6183, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3887, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5288, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8633, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9646, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5192, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.6599, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6538, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9165, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4450, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8206, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4789, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5112, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7092, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= tensor(0.9844, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4867, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7990, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8568, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6618, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9597, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4681, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8139, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3520, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7889, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0378, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1275, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4667, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3223, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0880, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.3818, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2384, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2500, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4271, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7291, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7441, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5159, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9738, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.7905, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8797, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7112, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6677, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6069, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2832, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4900, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9651, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.7876, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7441, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1441, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9660, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.2182, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7639, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5616, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.1744, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.1954, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9063, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2401, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1363, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.5237, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.3328, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6155, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6954, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.5801, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5781, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8393, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.5526, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1892, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.8924, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9890, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.8998, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.5340, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3310, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.0075, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5268, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.7719, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.7868, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.4623, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0863, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.3669, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.6433, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2043, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0333, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.8988, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1107, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9459, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7191, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.2902, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4372, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7076, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.5402, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6571, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7532, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.7730, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3346, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.6169, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9004, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3638, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3767, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7935, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4679, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4686, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5352, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.0711, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1006, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1124, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8854, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7809, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3885, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3159, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6622, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.4366, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4817, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5074, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1858, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7228, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2082, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9501, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5742, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1141, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7370, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6447, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6547, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5031, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6986, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0419, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2828, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.1995, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6139, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7688, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6268, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5857, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0643, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5827, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6398, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8637, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9197, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3970, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4500, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3449, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5757, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7709, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7797, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.7040, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6420, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7203, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4394, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4814, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7212, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5921, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4339, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.8080, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6105, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.3804, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.5093, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4793, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8147, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7401, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9520, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.5640, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.4737, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8381, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0331, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1248, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7358, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.7070, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0436, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(0.9383, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8007, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8624, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.8842, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0756, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2277, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0853, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4598, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.0912, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4543, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.2515, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4555, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1585, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3017, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9032, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8829, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.3050, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3893, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4302, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9472, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.4111, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7841, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8358, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= tensor(1.7750, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.4413, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5444, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.4769, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0479, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8497, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1218, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9808, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8391, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.6032, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7891, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0402, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3862, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2440, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0575, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1997, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3457, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.3491, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8528, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.6331, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0277, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.7775, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0915, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8354, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9679, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(3.0909, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2694, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3633, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.6294, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3439, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.1606, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3068, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9625, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(3.0913, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8665, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9688, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.7145, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3625, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.4878, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.8571, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.7849, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.9947, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9387, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9104, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.5668, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.9974, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9467, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9839, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.0900, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(3.9226, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9797, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9593, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9965, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6115, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2267, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1190, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.3252, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.4007, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.9012, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.9553, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.5796, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.4916, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2270, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.6869, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1033, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.9005, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.7079, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.6189, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.8116, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.0731, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(4.1314, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.6257, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1402, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.6358, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.3047, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0038, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1843, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.8637, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.5778, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1437, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.5038, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.0913, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1511, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.3017, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.1240, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(3.6114, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6581, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0963, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.0622, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(2.4526, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2075, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9355, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7247, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2044, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.0943, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.7941, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6937, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "loss= tensor(1.8008, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(2.2542, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1168, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(0.9360, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.8285, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.6606, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1528, grad_fn=<MseLossBackward0>)\n",
      "loss= tensor(1.1522, grad_fn=<MseLossBackward0>)\n",
      "i= 8\n",
      "Epoch= 100\n",
      "Your final loss (0.379140) must be no more than 0.0200 to receive full points for this question\n",
      "\n",
      "### Question q2: 2/6 ###\n",
      "\n",
      "Finished at 11:01:58\n",
      "\n",
      "Provisional grades\n",
      "==================\n",
      "Question q2: 2/6\n",
      "------------------\n",
      "Total: 2/6\n",
      "\n",
      "Your grades are NOT yet registered.  To register your grades, make sure\n",
      "to follow your instructor's guidelines to receive credit on your project.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run autograder.py -q q2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
