from torch import no_grad, stack
from torch.utils.data import DataLoader
from torch.nn import Module


"""
Функции, которые вам следует использовать.
Пожалуйста, не импортируйте любые другие функции или модули Torch.
Ваш код не пройдет проверку, если autograder обнаружит какое-либо измененение
строк импорта
"""
from torch.nn import Parameter, Linear
from torch import optim, tensor, tensordot, empty, ones
from torch.nn.functional import cross_entropy, relu, mse_loss
from torch import movedim


class PerceptronModel(Module):
    def __init__(self, dimensions):
        """
        Инициализирует новый экземпляр класса PerceptronModel.

        Персептрон классифицирует точки данных как принадлежащие определенному
        классу (+1) или нет (-1). `dimensions` — это размерность данных.
        Например, dimensions=2 будет означать, что персептрон должен классифицировать
        2D-точки.

        Чтобы автогрейдер (autograder) мог идентфицировать веса, инициализируйте
        их как объект pytorch Parameter следующим образом:

        Parameter(weight_vector),

        где weight_vector — это тензор pytorch размерности 'dimensions'.

        Подсказка: можно использовать ones(dim) для создания тензора размерности dim.
        
        """
        super(PerceptronModel, self).__init__()
        
        
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
      

    def get_weights(self):
        """
        Возвращает экземпляр Parameter с текущими весами персептрона.
        """
        return self.w

    def run(self, x):
        """
        Вычисляет оценку n=x*w, назначенную персептроном точке данных x.

        Входные данные:
            x: вектор с формой (1 x dimensions)
        Возвращает: одно число (оценку)

        Здесь может быть полезна функция pytorch `tensordot`.
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
       


    def get_prediction(self, x):
        """
        Вычисляет прогнозируемый класс пинадлежности одной точки данных `x`.

        Возвращает: 1 или -1
        """
        
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
       



    def train(self, dataset):
        """
        Обучение персептрона до сходимости.
        
        Выполняйте итерации по данным с помощью DataLoader, чтобы
        извлекать порции данных, на которых нужно обучаться.

        Каждая выборка  данных dataloader имеет вид {'x': features, 'label': label}, где 
        label — истинная метка данных, которую  нужно предсказать на основе признаков x.
        """        
        with no_grad():
            dataloader = DataLoader(dataset, batch_size=1, shuffle=True)
            
            "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
            
             

class RegressionModel(Module):
    """
    Модель нейронной сети для аппроксимации функции, которая отображает 
    действительные числа в действительные числа. Сеть должна быть достаточно
    большой, чтобы иметь возможность аппроксимировать sin(x) на интервале
    [-2pi, 2pi] с разумной точностью.
    """
   
    def __init__(self):
        
        # Здесь инициализируйте параметры вашей модели нейросети
       
        super(RegressionModel,self).__init__()
        
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        


    def forward(self, x):
        """
        Запускает модель для блока (batch) входных данных.

        Входные данные:
            x: блок данных с формой (batch_size x 1)
        Возвращает:
            блок с формой (batch_size x 1), содержащий прогнозируемые значения y    
        """
               
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        

    
    def get_loss(self, x, y):
        """
        Вычисляет среднеквадратические потери для блока входных данных.

        Входные данные:
            x: блок данных с формой (batch_size x 1)
            y: блок данных с формой (batch_size x 1), содержащий истинные значения y,
            которые будут использоваться для обучения
        Возвращает: тензор размером 1, содержащий потери
        """
        
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        
  

    def train(self, dataset):
        """
        Обучение модели.

        Чтобы получить блок данных, создайте объект DataLoader и передайте ему `dataset`, а также требуемый размер блока.
        Просмотрите класс PerceptronModel как руководство по использованию DataLoader

        Каждая выборка dataloader будет иметь вид {'x': features, 'label': label}, где label
        — это истинное значение (метка), которое должна предсказать модель нейросети.

        Входные данные:
            dataset:  набор данных PyTorch, содержащий данные для обучения
            
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
       
        

   
class DigitClassificationModel(Module):
    """
    Модель классификации рукописных цифр с использованием набора данных MNIST.

    Каждая рукописная цифра представляет собой изображение в оттенках серого 
    размером 28x28 пикселей, которое преобразовано в 784-мерный вектор для целей 
    этой модели нейросети. Каждый элемент вектора представляет собой число с
    плавающей точкой от 0 до 1.

    Цель состоит в том, чтобы отнести каждую цифру к одному из 10 классов (число от 0 до 9).

    (См. RegressionModel для получения дополнительной информации об API различных
     методов класса. Рекомендуется  реализовать RegressionModel перед
     работой над этим заданием.)
    """
    
    def __init__(self):
      
        # Здесь инициализируйте параметры вашей модели нейросети
        super().__init__()
        input_size = 28 * 28
        output_size = 10
        
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        
        


    def run(self, x):
        """
        Запускает модель для блока входных данных.

        Ваша модель должна формировать предсказание в виде тензора с формой
        (batch_size x 10), который содержит оценки предсказания. Более высокие оценки
        соответствуют большей вероятности принадлежности изображения к 
        определенному классу.

        Входные данные:
            x: тензор с формой (batch_size x 784)
        Выходные данные:
            тензор с формой (batch_size x 10), содержащий предсказанные оценки
            (также называемые логитами)
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        
    
    def get_loss(self, x, y):
        """
        Вычисляет потери для блока входных данных.

        Истинные метки `y` представляются в виде тензора с формой
        (batch_size x 10). Каждая строка тензора — это one-hot вектор, кодирующий
        правильный класс изображения цифры (0-9).

        Входные данные:
            x: тензор с формой (batch_size x 784)
            y: тензор с формой (batch_size x 10)
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        
       
        

    def train(self, dataset):
        """
        Обучение модели.
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"

        



class LanguageIDModel(Module):
    """
    Модель для идентификации языка с гранулярностью в одно слово.

    (См. RegressionModel для получения дополнительной информации об API различных
     методов, используемых здесь. Мы рекомендуем вам реализовать RegressionModel перед
     работой над этой частью проекта.)
    """
    def __init__(self):
        
        # Наш набор данных содержит слова из пяти разных языков, а
        # объединенные алфавиты пяти языков содержат в общей сложности 47 уникальных
        # символов.
        # Вы можете ссылаться на self.num_chars или len(self.languages) в своем коде
   
        self.num_chars = 47
        self.languages = ["English", "Spanish", "Finnish", "Dutch", "Polish"]
        super(LanguageIDModel, self).__init__()
        
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        
        
        "*** КОНЕЦ ВАШЕГО КОДА ***"
         
         
    def run(self, xs):
        """
        Запускает модель для блока (batch) входных данных.

        Хотя слова имеют разную длину, наша пред.обработка данных гарантирует,
        что в пределах бэтча все слова будут иметь одинаковую длину (L).
                
        Здесь `xs` список длины L. Каждый элемент `xs` это
        тензор с формой (batch_size x self.num_chars), где каждая строка 
        является векторным кодом символа. Например, если у нас
        есть бэтч из 8 трехбуквенных слов, где последнее слово «cat», то
        xs[1] будет тензором, содержащим 1 в позиции (7, 0). Здесь индекс
        7 отражает тот факт, что «cat» является последним словом в бэтче, а
        индекс 0 отражает тот факт, что буква «a» является начальной (0-й)
        буквой нашего объединенного алфавита..

        Ваша модель должна реализовать рекуррентную нейронную сеть, преобразующую 
        список `xs` в тензор скрытого состояния формы (batch_size x hidden_size), 
        где hidden_size размерность скрытого состояния. Затем она должна вычислить 
        тензор формы (batch_size x 5), содержащий оценки вероятности языка, где 
        более высокие значения соответствуют большей вероятности слова из 
        определенного языка .


        Входы:
            xs: список из L элементов (по одному на символ), где каждый элемент
                имеет форму (batch_size x self.num_chars)
        Возвращает:
            Тензор формы (batch_size x 5), содержащий предсказанные рейтинги языка
                (также называемые логитами - logits)
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        
        
        
        
    
    def get_loss(self, xs, y):
        """ 
        Вычисляет потери в пределах мини-блока примеров.

        Правильные метки `y` представлены тензором с формой (batch_size x 5).
        Каждая строка тензора — это "one-hot" вектор, кодирующий  язык.

        Входные данные:
        xs: список из L элементов (по одному на символ), где каждый элемент
        - это тензор формы (batch_size x self.num_chars)
        y: правильные метки в виде тензора с формой (batch_size x 5)
        Возвращает: потери
               
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        
    
    def train(self, dataset):
        """
        Обучение модели.
        
        Обратите внимание, что при использовании dataloader будет возвращаться тензор в форме
        (batch_size x length of word x self.num_chars). В тоже время  get_loss() и run() ожидают,
        что на входе тензор будет в форме (length of word x batch_size x self.num_chars).
        Это означает, что вам нужно поменять местами первые два измерения входного тензора.
        Это можно сделать с помощью функции movedim() следующим образом:    

        movedim(input_vector, initial_dimension_position, final_dimension_position)

        Детальнее см. документацию по torch.movedim()
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
        
        
        
        
def Convolve(input: tensor, weight: tensor):
    """
    Реализуйте двумерную свертку с заданными входами и весами.
    НЕ импортируйте никакие методы pytorch, которые напрямую реализуют свертку.
    Ваша реализация свертка должна быть выполнена только с помощью  уже 
    импортированных функций.

    Есть несколько способов реализовать свертку. Одним из возможных решений 
    является использование  'tensordot'.
    Если вы хотите индексировать тензор, вы можете сделать это следующим образом:

        tensor[y:y+height, x:x+width]

    Это вызов возвращает подтензор, первый элемент которого — tensor[y,x] 
    Подтензор имеет высоту 'height, и ширину 'width'
    """
    input_tensor_dimensions = input.shape
    weight_dimensions = weight.shape
    Output_Tensor = tensor(())
   
    "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"

    
    
    "*** КОНЕЦ ВАШЕГО КОДА ***"
    return Output_Tensor



class DigitConvolutionalModel(Module):
    """
    Модель для классификации рукописных цифр с использованием набора данных MNIST.

    Этот класс представляет собой  модель нейросети со сверточным слоем.
    Если Convolve() реализована правильно, эта модель должна быстро достичь  
    заданной точности на наборе данных MNIST .

    """
    

    def __init__(self):
        
        # Здесь инициализируйте параметры вашей модели нейросети
        super().__init__()
        output_size = 10

        self.convolution_weights = Parameter(ones((3, 3)))
        
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"


    def run(self, x):
        """
       
        Вызов сверточного слоя и преобразование его выхода  в "плоский "вектор 
        уже реализованы.
        Здесь вам следует рассматривать выход сверточного слоя x как обычный блок данных, 
        размером bz x 676, который далее обрабатывается полносвязными слоями, аналогичеыми
        классу DigitClassificationModel.
             
        """
        x = x.reshape(len(x), 28, 28)
        x = stack(list(map(lambda sample: Convolve(sample, self.convolution_weights), x)))
        x = x.flatten(start_dim=1)
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"

 

    def get_loss(self, x, y):
        """
        Вычисляет потери для блока входных данных.

        Истинные метки `y` представляются в виде тензора с формой
        (batch_size x 10). Каждая строка тензора — это one-hot вектор, кодирующий
        правильный класс изображения цифры (0-9).

        Входные данные:
            x: тензор с формой (batch_size x 784)
            y: тензор с формой (batch_size x 10)
        Возвращает: тензор потерь
        """
        
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"

        

    def train(self, dataset):
        """
        Обучение модели.
        """
       
        "*** ВСТАВЬТЕ ВАШ КОД СЮДА ***"
 
