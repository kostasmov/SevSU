{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные сети\n",
    "До сих пор мы работали с глубокими полносвязанными сетями и изучали различные стратегии оптимизации. Полносвязанные сети - хороший объект для экспериментов, потому что они простые с точки зрения программирования вычислений, но на практике часто применяют и другие архитектуры, в частности, сверточные сети.\n",
    "\n",
    "Реализуем несколько типов слоев, которые используются в сверточных сетях. Далее мы будем использовать эти слои для обучения сверточных сетей, используя множество данных CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проблемы выполнения первой ячеки\n",
    "\n",
    "Если при первом выполнении первой ячейки данного блокнота будет генерироваться сообщение:\n",
    "\n",
    "```bash \n",
    "Перейдите в директорию dlcv и выполните там команду:\n",
    "python setup.py build_ext --inplace\n",
    "Возможно вам также будет необходимо перезапустить iPython kernel\n",
    "```\n",
    "то необходимо выполнить компиляцию кода для быстрых функций свертки и пуллинга  с использованием указанной команды (при работе в ОС Windows должны быть установлены средства разработки на С++ 14.х \"Microsoft Build Tools for Visual Studio 2019\").\n",
    "Выполнить команду можно не только из командного окна среды Python, но также и из ячейки блокнота с помощью следующего кода\n",
    "```bash\n",
    "%cd dlcv\n",
    "!python setup.py build_ext --inplace\n",
    "%cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перейдите в директорию dlcv и выполните там команду:\n",
      "python setup.py build_ext --inplace\n",
      "Возможно вам также будет необходимо перезапустить iPython kernel\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Выполните начальные установки блокнота.\n",
    "# Внимание! Блокнот работает в версии Python 3.6!\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dlcv.classifiers.cnn import *\n",
    "from dlcv.data_utils import get_CIFAR10_data\n",
    "from dlcv.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from dlcv.layers import *\n",
    "from dlcv.fast_layers import *\n",
    "from dlcv.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # установка размеров графиков по умолчанию\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Для перезагрузки внешних модулей python;\n",
    "# см. http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" возвращает относительную ошибку\"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и предобработка данных CIFAR10\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свертка: наивное прямое распространение\n",
    "\n",
    "Ядром сверточной сети является операция свертки. В файле `dlcv/layers.py` реализуйте прямое распространение для сверточного слоя в функции `conv_forward_naive`.\n",
    "\n",
    "На данный момент вам не нужно слишком беспокоиться об эффективности; просто напишите код, реализующий свертку.\n",
    "\n",
    "Протестируйте свою реализацию, выполнив следующую ячейку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (3, 3, 4, 4)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = conv_forward_naive(x, w, b, conv_param)\n",
    "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
    "                           [-0.18387192, -0.2109216 ]],\n",
    "                          [[ 0.21027089,  0.21661097],\n",
    "                           [ 0.22847626,  0.23004637]],\n",
    "                          [[ 0.50813986,  0.54309974],\n",
    "                           [ 0.64082444,  0.67101435]]],\n",
    "                         [[[-0.98053589, -1.03143541],\n",
    "                           [-1.19128892, -1.24695841]],\n",
    "                          [[ 0.69108355,  0.66880383],\n",
    "                           [ 0.59480972,  0.56776003]],\n",
    "                          [[ 2.36270298,  2.36904306],\n",
    "                           [ 2.38090835,  2.38247847]]]])\n",
    "\n",
    "# Сравните результаты с требуемыми; ошибка должна быть около e-8\n",
    "print('Тестирование функции conv_forward_naive')\n",
    "print('Относительная ошибка: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка изображений с помощью сверток\n",
    "\n",
    "В качестве любопытного способа проверки вашей реализации, а также с целью лучшего понимания операций, которые выполняют сверточные слои, подадим на вход два изображения, и вручную настроим фильтры, которые выполняют общие операции обработки изображений (преобразование цветного изображения в градации серого и выделение границ на изображении). Прямое распространение изображений через сверточный слой  обеспечит применение этих операций к каждому из входных изображений. Для проверки работоспособности мы  визуализируем  результаты обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "from PIL import Image\n",
    "\n",
    "kitten = imread('kitten.jpg')\n",
    "puppy = imread('puppy.jpg')\n",
    "\n",
    "# изображение кошки широкое, поэтому делаем его обрезку\n",
    "d = kitten.shape[1] - kitten.shape[0]\n",
    "kitten_cropped = kitten[:, d//2:-d//2, :]\n",
    "\n",
    "img_size = 200   # Можно уменьшить, если будет работать медленно\n",
    "resized_puppy = np.array(Image.fromarray(puppy).resize((img_size, img_size)))\n",
    "resized_kitten = np.array(Image.fromarray(kitten_cropped).resize((img_size, img_size)))\n",
    "x = np.zeros((2, 3, img_size, img_size))\n",
    "x[0, :, :, :] = resized_puppy.transpose((2, 0, 1))\n",
    "x[1, :, :, :] = resized_kitten.transpose((2, 0, 1))\n",
    "\n",
    "# Начальная установка сверточных весов  двух фильтров размерами 3x3\n",
    "w = np.zeros((2, 3, 3, 3))\n",
    "\n",
    "# Первый фильтр преобразует изображение в оттенки серого.\n",
    "# Устанавливаем значения красного, зеленого и синего каналов фильтра.\n",
    "w[0, 0, :, :] = [[0, 0, 0], [0, 0.3, 0], [0, 0, 0]]\n",
    "w[0, 1, :, :] = [[0, 0, 0], [0, 0.6, 0], [0, 0, 0]]\n",
    "w[0, 2, :, :] = [[0, 0, 0], [0, 0.1, 0], [0, 0, 0]]\n",
    "\n",
    "# Второй фильтр выделяет горизонтальные края в канале синего цвета.\n",
    "w[1, 2, :, :] = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
    "\n",
    "# Вектор смещения. Нам не нужно смещение для оттенков серого,\n",
    "# но для фильтра, обнаруживающего края мы  добавим 128\n",
    "# к каждому выходу, чтобы значения не были отрицательными.\n",
    "b = np.array([0, 128])\n",
    "\n",
    "# Вычисляем результат свертки каждого входа из x с каждым фильтром из w,\n",
    "# смещаем на b и сохраняем результаты в out.\n",
    "out, _ = conv_forward_naive(x, w, b, {'stride': 1, 'pad': 1})\n",
    "\n",
    "def imshow_no_ax(img, normalize=True):\n",
    "    \"\"\" Отображение изображений в формате uint8 и удаления меток осей \"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# Отображение исходных изображений и результатов свертки\n",
    "plt.subplot(2, 3, 1)\n",
    "imshow_no_ax(puppy, normalize=False)\n",
    "plt.title('Исходное изображение')\n",
    "plt.subplot(2, 3, 2)\n",
    "imshow_no_ax(out[0, 0])\n",
    "plt.title('Полутоновое')\n",
    "plt.subplot(2, 3, 3)\n",
    "imshow_no_ax(out[0, 1])\n",
    "plt.title('Границы')\n",
    "plt.subplot(2, 3, 4)\n",
    "imshow_no_ax(kitten_cropped, normalize=False)\n",
    "plt.subplot(2, 3, 5)\n",
    "imshow_no_ax(out[1, 0])\n",
    "plt.subplot(2, 3, 6)\n",
    "imshow_no_ax(out[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свертка: наивное обратное распространение\n",
    "\n",
    "Реализуйте обратное распространение для операции свертки в функции `conv_backward_naive` в файле `dlcv/layers.py`. Вам не нужно слишком беспокоиться об эффективности вычислений.\n",
    "\n",
    "Запустите код в ячейке, чтобы протестировать обратное распространение с помощью проверки градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "w = np.random.randn(2, 3, 3, 3)\n",
    "b = np.random.randn(2,)\n",
    "dout = np.random.randn(4, 2, 5, 5)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward_naive(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_forward_naive(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_forward_naive(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "out, cache = conv_forward_naive(x, w, b, conv_param)\n",
    "dx, dw, db = conv_backward_naive(dout, cache)\n",
    "\n",
    "# Ошибки должны быть около e-8 или меньше.\n",
    "print('Тестирование функции conv_backward_naive')\n",
    "print('Относительная ошибка dx: ', rel_error(dx, dx_num))\n",
    "print('Относительная ошибка dw: ', rel_error(dw, dw_num))\n",
    "print('Относительная ошибка db error: ', rel_error(db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Макс-пулинг (max-pooling): наивное прямое распространение\n",
    "Реализуйте прямое распространение для операции max-pooling в функции `max_pool_forward_naive` в файле `dlcv/layers.py`. \n",
    "\n",
    "Проверьте реализацию, выполнив следующие действия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n",
    "\n",
    "out, _ = max_pool_forward_naive(x, pool_param)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [ 0.03157895,  0.04631579]]],\n",
    "                        [[[ 0.09052632,  0.10526316],\n",
    "                          [ 0.14947368,  0.16421053]],\n",
    "                         [[ 0.20842105,  0.22315789],\n",
    "                          [ 0.26736842,  0.28210526]],\n",
    "                         [[ 0.32631579,  0.34105263],\n",
    "                          [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "# Сравните результаты с требуемыми. Разница должна быть порядка e-8.\n",
    "print('Тестирование функции max_pool_forward_naive:')\n",
    "print('Относительная ошибка выхода: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Макс-пулинг: наивное обратное распространение \n",
    "\n",
    "Реализуйте обратный проход для операции max-pooling в функции `max_pool_backward_naive` в файле `dlcv/layers.py`. \n",
    "\n",
    "Протестируйте свою реализацию с помощью проверки градиента, выполнив следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(3, 2, 8, 8)\n",
    "dout = np.random.randn(3, 2, 4, 4)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: max_pool_forward_naive(x, pool_param)[0], x, dout)\n",
    "\n",
    "out, cache = max_pool_forward_naive(x, pool_param)\n",
    "dx = max_pool_backward_naive(dout, cache)\n",
    "\n",
    "# Ваша ошибка должна быть порядка e-12\n",
    "print('Тестирование функции max_pool_backward_naive:')\n",
    "print('Ошибка dx: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Быстрые слои\n",
    "\n",
    "Реализации свертки и пулинга в виде наивных функций, определенных вами выше, могут быть медленными. В файле `dlcv/fast_layers.py` подготовлены быстрые реализации прямого и обратного распространения для свертки и пулинга. \n",
    "Реализация быстрой свертки осуществляется с помощью расширения на Cython (файлы с расширением .pyx). \n",
    "\n",
    "API для быстрых версий слоев свертки и пулинга в точности совпадает с наивными версиями, которые вы реализовали выше: функция прямого распространения принимает данные, веса и параметры и формирует выходы и кеш; функция обратного распространения получает производные восходящего потока и кэш и вычисляет градиенты по отношению к данным и весам.\n",
    "\n",
    "ПРИМЕЧАНИЕ. Быстрая реализация для пулинга будет выполняться оптимально только в том случае, если области пулинга не перекрываются. Если эти условия не выполняются, реализация быстрого пулинга не будет быстрее, чем наивная реализация.\n",
    "\n",
    "Вы можете сравнить производительность наивных и быстрых версий слоев, выполнив следующие действия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ошибки должны быть около e-9 или менее\n",
    "from dlcv.fast_layers import conv_forward_fast, conv_backward_fast\n",
    "from time import time\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(100, 3, 31, 31)\n",
    "w = np.random.randn(25, 3, 3, 3)\n",
    "b = np.random.randn(25,)\n",
    "dout = np.random.randn(100, 25, 16, 16)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = conv_forward_naive(x, w, b, conv_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = conv_forward_fast(x, w, b, conv_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Тестирование функции conv_forward_fast:')\n",
    "print('Наивная реализация: %fs' % (t1 - t0))\n",
    "print('Быстрая реализация: %fs' % (t2 - t1))\n",
    "print('Увеличение скорости: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Относительная ошибка: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive, dw_naive, db_naive = conv_backward_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast, dw_fast, db_fast = conv_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nТестирование функции conv_backward_fast:')\n",
    "print('Наивная реализация: %fs' % (t1 - t0))\n",
    "print('Быстрая реализация: %fs' % (t2 - t1))\n",
    "print('Увеличение скорости: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Ошибка dx: ', rel_error(dx_naive, dx_fast))\n",
    "print('Ошибка dw: ', rel_error(dw_naive, dw_fast))\n",
    "print('Ошибка db: ', rel_error(db_naive, db_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ошибки должны быть близки к  0.0\n",
    "from dlcv.fast_layers import max_pool_forward_fast, max_pool_backward_fast\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(100, 3, 32, 32)\n",
    "dout = np.random.randn(100, 3, 16, 16)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = max_pool_forward_naive(x, pool_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = max_pool_forward_fast(x, pool_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Тестирование функции pool_forward_fast:')\n",
    "print('Наивная реализация: %fs' % (t1 - t0))\n",
    "print('Быстрая реализация: %fs' % (t2 - t1))\n",
    "print('Увеличение скорости: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Относительная ошибка: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive = max_pool_backward_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast = max_pool_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nТестирование функции pool_backward_fast:')\n",
    "print('Наивная реализация: %fs' % (t1 - t0))\n",
    "print('Быстрая реализация: %fs' % (t2 - t1))\n",
    "print('Увеличение скорости: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Относительная ошибка dx: ', rel_error(dx_naive, dx_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные \"сэндвич-слои\"\n",
    "Ранее мы ввели понятие \"сэндвич\" слоев , которые объединяют несколько операций в широко используемых шаблонах слоев. В файле `dlcv / layer_utils.py` вы найдете \"сэндвич-слои\", которые реализуют несколько часто используемых шаблонов для сверточных сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcv.layer_utils import conv_relu_pool_forward, conv_relu_pool_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = conv_relu_pool_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], b, dout)\n",
    "\n",
    "# Относительные ошибки должны быть около e-8 или менее\n",
    "print('Тестирование функции conv_relu_pool')\n",
    "print('Относительная ошибка dx: ', rel_error(dx_num, dx))\n",
    "print('Относительная ошибка dw: ', rel_error(dw_num, dw))\n",
    "print('Относительная ошибка db: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcv.layer_utils import conv_relu_forward, conv_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 8, 8)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "out, cache = conv_relu_forward(x, w, b, conv_param)\n",
    "dx, dw, db = conv_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_forward(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_forward(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_forward(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "# Относительные ошибки должны быть около e-8 или менее\n",
    "print('Тестирование функции conv_relu:')\n",
    "print('Относительная ошибка dx: ', rel_error(dx_num, dx))\n",
    "print('Относительная ошибка dw: ', rel_error(dw_num, dw))\n",
    "print('Относительная ошибка db: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Трехслойная ConvNet\n",
    "Теперь, когда Вы реализовали все необходимые слои,  можно объединить их в простую сверточную сеть.\n",
    "\n",
    "Откройте файл `dlcv / classifiers / cnn.py` и завершите реализацию класса` ThreeLayerConvNet`. Помните, что вы можете использовать быстрые / сэндвич-слои (уже импортированные в вашей реализации). Запустите  ячейки ниже, чтобы выполнить отладку:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка значения потерь\n",
    "\n",
    "После построения новой сети, одной из первых вещей, которую вы должны сделать, является проверка значения потерь на здравый смысл. Когда мы используем потери softmax, мы ожидаем, что потери для случайных начальных весов (при отсутствие регуляризации) будет примерно равны `log(C)` для `C` классов . Когда мы добавляем регуляризацию, потери должны повышаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeLayerConvNet()\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 3, 32, 32)\n",
    "y = np.random.randint(10, size=N)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Начальные потери (без регуляризации): ', loss)\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Начальные потери (с регуляризацией): ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка градиента\n",
    "\n",
    "После проверки потерь, сделайте проверку численного градиента, чтобы убедиться, что  обратное распространение реализовано правильно. Когда вы используете численную проверку градиента, вы должны использовать небольшое количество искусственных данных и небольшое количество нейронов на каждом уровне. Примечание: правильные реализации могут  иметь относительные ошибки  порядка e-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "input_dim = (3, 16, 16)\n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "np.random.seed(231)\n",
    "X = np.random.randn(num_inputs, *input_dim)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters=3, filter_size=3,\n",
    "                          input_dim=input_dim, hidden_dim=7,\n",
    "                          dtype=np.float64)\n",
    "loss, grads = model.loss(X, y)\n",
    "# Ошибки должны быть маленькими, но корректные реализации \n",
    "# могут иметь относительную ошибку порядка e-2\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s максимальная относительная ошибка: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переобучение на малом объеме данных\n",
    "\n",
    "Хороший трюк проверки работоспособности модели сети состоит в том, чтобы обучить вашу модель всего на нескольких примерах. Вы должны достичь переобучения на  небольшом наборе данных, что приведет к  высокой точности обучения и сравнительно низкой точности валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "num_train = 100\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvNet(weight_scale=1e-2)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=15, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графики потерь, точности обучения и точности валидации должны демонстрировать четкое переобучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Итерации')\n",
    "plt.ylabel('Потери')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['обучение', 'валидация'], loc='upper left')\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('Точность')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение сети\n",
    "Обучая трехслойную сверточную сеть в течение одной эпохи, вы должны достичь более 40% точности на обучающем наборе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=500, reg=0.001)\n",
    "\n",
    "solver = Solver(model, data,\n",
    "                num_epochs=1, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=20)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация фильтров\n",
    "Для понимания низкоуровневых признаков, которые способна распознавать после обучения, можно визуализировать сверточные фильтры первого слоя обученной сети, выполнив следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcv.vis_utils import visualize_grid\n",
    "\n",
    "grid = visualize_grid(model.params['W1'].transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пространственная блочная нормализация\n",
    "\n",
    "Мы уже видели, что блочная нормализация - полезный метод обучения глубоких полносвязанных сетей. Как предложено  работе [1], блочная нормализация также может быть использована в сверточных сетях, но нам нужно немного ее адаптировать; модификация будет называться \"пространственной блочной нормализацией\".\n",
    "\n",
    "Обычная блочная нормализация получает на вход массив формы (N, D) и формирует выходной массив формы (N, D), где нормализация выполняется  в отношении каждого признака из D путем вычисления статистик по размеру мини-блока N. Для данных, поступающих из сверточных слоев, процедура блочной нормализации должна  получать на вход массив формы (N, C, H, W) и формировать выход формы (N, C, H, W), где размерность N задает размер мини-блока, а размеры (H, W) дают пространственный размер карты признаков.\n",
    "\n",
    "Если карта признаков была создана с использованием сверток, то мы ожидаем, что статистика каждого канала признаков будет относительно последовательной как между разными изображениями, так и в разных местах внутри одного и того же изображения. Поэтому пространственная блочная нормализация  вычисляет среднее значение и дисперсию для каждого из каналов признаков C, вычисляя средние как по N, так и по пространственным размерам H и W.\n",
    "\n",
    "[1] [Sergey Ioffe and Christian Szegedy, \"Batch Normalization: Accelerating Deep Network Training by Reducing\n",
    "Internal Covariate Shift\", ICML 2015.](https://arxiv.org/abs/1502.03167)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пространственная блочная нормализация: прямое распространение\n",
    "\n",
    "В файле `dlcv/layers.py`, реализуйте прямое распространение для пространственной блочной нормализации  в функции `spatial_batchnorm_forward`. Проверьте свою реализацию, выполнив следующие действия:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "# Проверьте средние и дисперсии   признаков\n",
    "# прямого пути как до, так и после блочной пространственной нормализации\n",
    "\n",
    "N, C, H, W = 2, 3, 4, 5\n",
    "x = 4 * np.random.randn(N, C, H, W) + 10\n",
    "\n",
    "print('Перед пространственной блочной нормализации:')\n",
    "print('  Форма: ', x.shape)\n",
    "print('  Средние: ', x.mean(axis=(0, 2, 3)))\n",
    "print('  Стандартное отклонение: ', x.std(axis=(0, 2, 3)))\n",
    "\n",
    "# Средние должны быть близки к нулю, а дисперсии - близко к 1\n",
    "gamma, beta = np.ones(C), np.zeros(C)\n",
    "bn_param = {'mode': 'train'}\n",
    "out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "print('После пространственной блочной нормализации:')\n",
    "print('  Форма: ', out.shape)\n",
    "print('  Средние: ', out.mean(axis=(0, 2, 3)))\n",
    "print('  Стандартное отклонение: ', out.std(axis=(0, 2, 3)))\n",
    "\n",
    "# Средние должны быть близки к beta, а дисперсии - близко к gamma\n",
    "gamma, beta = np.asarray([3, 4, 5]), np.asarray([6, 7, 8])\n",
    "out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "print('После пространственной блочной нормализации (не тривиальные gamma, beta):')\n",
    "print('  Форма: ', out.shape)\n",
    "print('  Средние: ', out.mean(axis=(0, 2, 3)))\n",
    "print('  Стандартное отклонение: ', out.std(axis=(0, 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "# Проверьте прямой путь в режиме тестирования, выполняя прямой путь\n",
    "# режима обучения много раз, чтобы сгладить скользящие средние, а затем\n",
    "# проверьте средние и дисперсии активаций после выполнения прямого распространения \n",
    "# в тестовом режиме.\n",
    "N, C, H, W = 10, 4, 11, 12\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "gamma = np.ones(C)\n",
    "beta = np.zeros(C)\n",
    "for t in range(50):\n",
    "  x = 2.3 * np.random.randn(N, C, H, W) + 13\n",
    "  spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "bn_param['mode'] = 'test'\n",
    "x = 2.3 * np.random.randn(N, C, H, W) + 13\n",
    "a_norm, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "\n",
    "\n",
    "# Средние должны быть близки к нулю, а дисперсии близки к 1\n",
    "print('После пространственной блочной нормализацией  (режим test):')\n",
    "print('  Средние: ', a_norm.mean(axis=(0, 2, 3)))\n",
    "print('  Стандартное отклонение: ', a_norm.std(axis=(0, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пространственная блочная нормализация: обратное распространение\n",
    "В файле `dlcv / layers.py`, реализуйте обратное распространение для пространственной блочной нормализациив в функции` space_batchnorm_backward`. Чтобы проверить реализацию, выполните следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, C, H, W = 2, 3, 4, 5\n",
    "x = 5 * np.random.randn(N, C, H, W) + 12\n",
    "gamma = np.random.randn(C)\n",
    "beta = np.random.randn(C)\n",
    "dout = np.random.randn(N, C, H, W)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "fx = lambda x: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fg = lambda a: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fb = lambda b: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta, dout)\n",
    "\n",
    "# Ошибки должны быть  между 1e-12 ~ 1e-06\n",
    "_, cache = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "dx, dgamma, dbeta = spatial_batchnorm_backward(dout, cache)\n",
    "print('Относительная ошибка dx: ', rel_error(dx_num, dx))\n",
    "print('Относительная ошибка dgamma: ', rel_error(da_num, dgamma))\n",
    "print('Оносительная ошибка dbeta: ', rel_error(db_num, dbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конец блокнота\n",
    "\n",
    "Задания в нижеследующей части блокнота выполняются факультативно!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация группы\n",
    "Ранее мы упоминали, что нормализация на слое — это альтернативный метод нормализации, который смягчает ограничения размера пакета блочной нормализации. Однако, как заметили авторы [2], нормализация на слое не работает так же хорошо, как блочная нормализация при использовании со сверточными слоями:\n",
    "\n",
    ">В полносвязанных слоях все скрытые элементы слоя имеют тенденцию вносить одинаковый вклад в окончательный результат предсказания, а рецентрирование и ремасштабирование суммируемых входных данных в слое работает хорошо. Однако предположение о подобных вкладах не справедливо для сверточных нейронных сетей. Большое количество скрытых нейронов, чьи рецептивные поля расположены вблизи границы изображения, редко срабатывают и, таким образом, имеют сильно отличающуюся статистику от остальных скрытых нейронов в том же слое.\n",
    "\n",
    "Авторы [3] предлагают промежуточный подход. В отличие от нормализации на слое, где  нормализуются все признаки для каждого примера данных, они предлагают последовательное разделение каждого признака для каждого примера данных на G групп и нормализацию в каждой группе для каждого примера данных.\n",
    "\n",
    "![Сравнение методов нормализации, обсуждавшихся до сих пор](norm.png)\n",
    "<center>Визуальное сравнение методов нормализации, обсуждавшихся до сих пор (изображение отредактировано из [3])</center>\n",
    "\n",
    "Несмотря на то, что внутри каждой группы все еще делается предположение о равном вкладе, авторы предполагают, что это не так проблематично, поскольку внутри признаков возникает врожденная группировка для визуального распознавания. Одним из примеров, которые они используют, чтобы проиллюстрировать это, является то, что многие высокоэффективные признаки, созданные вручную в традиционном компьютерном зрении, имеют элементы, которые явно сгруппированы вместе. Возьмем, к примеру, гистограмму ориентированных градиентов [4] — после вычисления гистограмм для каждого пространственно локального блока каждая гистограмма для каждого блока нормализуется перед объединением вместе для формирования окончательного вектора признаков.\n",
    "\n",
    "Ниже в ячейках блокнота вам необходимо реализовать нормализацию группы. \n",
    "\n",
    "[2] [Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"Layer Normalization.\" stat 1050 (2016): 21.](https://arxiv.org/pdf/1607.06450.pdf)\n",
    "\n",
    "\n",
    "[3] [Wu, Yuxin, and Kaiming He. \"Group Normalization.\" arXiv preprint arXiv:1803.08494 (2018).](https://arxiv.org/abs/1803.08494)\n",
    "\n",
    "\n",
    "[4] [N. Dalal and B. Triggs. Histograms of oriented gradients for\n",
    "human detection. In Computer Vision and Pattern Recognition\n",
    "(CVPR), 2005.](https://ieeexplore.ieee.org/abstract/document/1467360/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация группы: прямое распространение\n",
    "\n",
    "В файле  `dlcv/layers.py`, реализуйте прямое распространение для нормализации группы в функции `spatial_groupnorm_forward`. Проверьте вашу реализацию, выполнив следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "# Проверяем прямое распространение в режиме обучения, оценив средние значения и отклонения\n",
    "# признаков как до, так и после пространственной групповой нормализации\n",
    "\n",
    "N, C, H, W = 2, 6, 4, 5\n",
    "G = 2\n",
    "x = 4 * np.random.randn(N, C, H, W) + 10\n",
    "x_g = x.reshape((N*G,-1))\n",
    "print('Перед пространственной нормализацией группы:')\n",
    "print('  Форма: ', x.shape)\n",
    "print('  Средние: ', x_g.mean(axis=1))\n",
    "print('  Стандартные отклонения: ', x_g.std(axis=1))\n",
    "\n",
    "# Средние должны быть близки к нулю, а стандартные отклонения к единице\n",
    "gamma, beta = np.ones((1,C,1,1)), np.zeros((1,C,1,1))\n",
    "bn_param = {'mode': 'train'}\n",
    "\n",
    "out, _ = spatial_groupnorm_forward(x, gamma, beta, G, bn_param)\n",
    "out_g = out.reshape((N*G,-1))\n",
    "print('После пространственной нормализацией группы:')\n",
    "print('  Форма: ', out.shape)\n",
    "print('  Средние: ', out_g.mean(axis=1))\n",
    "print('  Стандартные отклонения: ', out_g.std(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Пространственная нормализация группы: обратное распространение\n",
    "В файле `dlcv/layers.py`, реализуйте обратное распространение для пространственной нормализации группы в функции  `spatial_groupnorm_backward`. Выполните следующее, чтобы проверить свою реализацию путем проверки градиентов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, C, H, W = 2, 6, 4, 5\n",
    "G = 2\n",
    "x = 5 * np.random.randn(N, C, H, W) + 12\n",
    "gamma = np.random.randn(1,C,1,1)\n",
    "beta = np.random.randn(1,C,1,1)\n",
    "dout = np.random.randn(N, C, H, W)\n",
    "\n",
    "gn_param = {}\n",
    "fx = lambda x: spatial_groupnorm_forward(x, gamma, beta, G, gn_param)[0]\n",
    "fg = lambda a: spatial_groupnorm_forward(x, gamma, beta, G, gn_param)[0]\n",
    "fb = lambda b: spatial_groupnorm_forward(x, gamma, beta, G, gn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta, dout)\n",
    "\n",
    "_, cache = spatial_groupnorm_forward(x, gamma, beta, G, gn_param)\n",
    "dx, dgamma, dbeta = spatial_groupnorm_backward(dout, cache)\n",
    "# Ошибки долны быть в пределах 1e-12~1e-07\n",
    "print('Относительная ошибка dx: ', rel_error(dx_num, dx))\n",
    "print('Относительная ошибка dgamma: ', rel_error(da_num, dgamma))\n",
    "print('Относительная ошибка dbeta: ', rel_error(db_num, dbeta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
