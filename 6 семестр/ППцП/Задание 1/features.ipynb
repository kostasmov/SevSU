{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простые обучаемые классификаторы с использованием признаков изображений \n",
    "\n",
    "Выполните задания блокнота и защитите результаты. Полностью заполненный блокнот необходимо сохранить и загрузить в ЭОС.\n",
    "\n",
    "Мы видели, что мы можем достичь обоснованной эффективности решения задачи классификации изображений путем обучения линейного классификатора, используя пиксели входного изображения. В этом задании мы повысим эффективность классификации  путем обучения классификаторов не на исходным пикселях, а на основе признаков, которые вычисляются в ходе анализа изображений.\n",
    "\n",
    "Все решения этого задания будут выполняться непосредственно в этом блокноте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "from dlcv.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # установка размеров графиков по умолчанию\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# для перезагрузки внешних модули python;\n",
    "# см. http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Аналочно предыдущим заданиям, загрузим базу CIFAF-10 c диска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcv.features import color_histogram_hsv, hog_feature\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Функция загружает базу данных изображений CIFAR10, разбивает её на три части\n",
    "    и возвращает массивы обучающих данных - X_train, y_train,\n",
    "    массивы валидационных данных - X_val, y_val, \n",
    "    массивы данных для тестирования - X_test, y_test    \n",
    "    \"\"\"\n",
    "    cifar10_dir = 'dlcv/datasets/cifar-10-batches-py'\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # формируем массивы данных для ообучения, валидации и тетирования\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Очистка переменных для предотвращения повторной загрузки данных\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Очистка ранее загруженных данных')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение признаков\n",
    "\n",
    "Для каждого изображения будем вычислять гистограмму ориентированных градиентов (HOG), а также гистограмму цветов (HOC) с использованием шкалы оттенков цветового пространства HSV. Конечный вектор признаков для каждого изображения формируется путем конкатенации векторов гистограмм HOG и HOC.\n",
    "\n",
    "Приближенно, HOG  фиксирует текстуру изображения, игнорируя цветовую информацию, а гистограмма цветов фиксирует рапределение цветов изображения при игнорировании текстуры. В результате мы ожидаем, что совместное использование 2-х гистограмм должно работать лучше. Проверка этого предположения и есть цель этого задания.\n",
    "\n",
    "Функции `hog_feature` и` color_histogram_hsv` работают с одним и тем же\n",
    "изображением и возвращают вектор признаков для этого изображения. Функция `extract_features`\n",
    "вопринимает множество изображений и список признаковых функций и применяет каждую функцию  к изображению, сохраняя результаты в матрице, где каждый столбец является конкатенацией всех векторов признаков для одного изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcv.features import *\n",
    "\n",
    "num_color_bins = 10 # число столбцов гистограммы НОС\n",
    "# сформируем список признаковых функций \n",
    "feature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]\n",
    "# применим каждую признаковую функцию из списка и получим конкатенированные признаковые представления\n",
    "X_train_feats = extract_features(X_train, feature_fns, verbose=True)    # обучающая матрица признаков\n",
    "X_val_feats = extract_features(X_val, feature_fns)                      # валидационная матрица признаков\n",
    "X_test_feats = extract_features(X_test, feature_fns)                    # матрица признаков для тестирования\n",
    "\n",
    "# Предобработка признаов: Вычитание среднего признака\n",
    "mean_feat = np.mean(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats -= mean_feat\n",
    "X_val_feats -= mean_feat\n",
    "X_test_feats -= mean_feat\n",
    "\n",
    "# Предобработка: Деление на стандартное отклонеине. Это обеспечивает для каждого признака\n",
    "# примерно один и тот же масштаб.\n",
    "std_feat = np.std(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats /= std_feat\n",
    "X_val_feats /= std_feat\n",
    "X_test_feats /= std_feat\n",
    "\n",
    "# Предобработка: Разширение размера для добавления смещения (трюк со смещением)\n",
    "X_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])\n",
    "X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])\n",
    "X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение SVM классификатора на признаках изображений\n",
    "\n",
    "Используя многоклассовый SVM классификатор, разработанный ранее, обучите его с использованием признаков, извлеченных из изображений с использованием гистограмм цветов и направленных градиентов; результаты классификации должны быть лучше, чем  при обучении SVM непосредственно с использованием пикселей изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте валидационное множество для выбора скорости обучения и коэффициента регуляризации\n",
    "from dlcv.classifiers.linear_classifier import LinearSVM\n",
    "\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_svm = None\n",
    "\n",
    "#learning_rates = [1e-9, 1e-8, 1e-7]\n",
    "#regularization_strengths = [5e4, 5e5, 5e6]\n",
    "\n",
    "learning_rates = [1e-7, 2e-7, 4e-7, 8e-7]\n",
    "regularization_strengths = [5e3, 1e4, 2e4, 8e4, 16e4]\n",
    "\n",
    "################################################################################\n",
    "# ЗАДАНИЕ:                                                                     #\n",
    "# Используйте валидационное множество для выбора скорости обучения и           #\n",
    "# коэффициента регуляризации. Это аналогично тому, как вы искали наилучшие     #\n",
    "# значения скорости обучения и  коэффициента регуляризации для SVM             #\n",
    "# классификатора; сохраните наилучший классификатор  в best_svm.               #\n",
    "# Вы также можете варьировать число столбцов гистограммы цветов. При           # \n",
    "# тщательном обучении вы должны получить валидацинную точность около 0.42.     #\n",
    "################################################################################\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        svm = LinearSVM()\n",
    "        \n",
    "        loss_hist = svm.train(X_train_feats, y_train, learning_rate=lr, reg=reg, num_iters=800, verbose=True)\n",
    "        y_train_pred = svm.predict(X_train_feats)\n",
    "        \n",
    "        train_accuracy=np.mean(y_train == y_train_pred)\n",
    "        print('lr=%e reg=%e' %(lr,reg))\n",
    "        print('Точность обучения: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "        y_val_pred = svm.predict(X_val_feats)\n",
    "        val_accuracy=np.mean(y_val == y_val_pred)\n",
    "        if val_accuracy>best_val:\n",
    "            best_val=val_accuracy\n",
    "            best_svm=svm\n",
    "        print('Валидационная точность: %f' % (np.mean(y_val == y_val_pred), ))\n",
    "        results[(lr,reg)]=(train_accuracy,val_accuracy)\n",
    "\n",
    "################################################################################\n",
    "#                              КОНЕЦ ВАШЕГО КОДА                               #\n",
    "################################################################################\n",
    "\n",
    "# Вывод результатов.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e точность обучения: %f валидационная точность: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('Наилучшая валидационная точность полученная в ходе кросс-валидации: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка обученного классификатора на тестовом множесте\n",
    "y_test_pred = best_svm.predict(X_test_feats)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важным способом развития интуиции в отношении понимания работы алгоритма является\n",
    "# визуализуализация ошибок, которые он совершает. Визуализация ниже демонстрирует примеры\n",
    "# изображений, которые неправильно классифицируются текущей версией программы. Первый столбец\n",
    "# показывает изображения, которым программа  присвоила метку «самолет», но чьи настоящие метки\n",
    "# таковыми не являются.\n",
    "\n",
    "examples_per_class = 8\n",
    "classes = ['самолет', 'авто', 'птица', 'кошка', 'олень', 'собака', 'лягушка', 'лошадь', 'судно', 'грузовик']\n",
    "for cls, cls_name in enumerate(classes):\n",
    "    idxs = np.where((y_test != cls) & (y_test_pred == cls))[0]\n",
    "    idxs = np.random.choice(idxs, examples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1)\n",
    "        plt.imshow(X_test[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 1:\n",
    "\n",
    "Опишите результаты ошибочной классификации, которые Вы наблюдаете. Они имеют обоснование?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение нейросети на признаках изображений\n",
    "\n",
    "Эта часть блокнота в данном задании не выполняется!!!\n",
    "\n",
    "Ранее Вы видели, что  двухслойная нейронная сеть, обучаемая  непосредственно на пикселях изображения, обеспечивала более высокую точность классификации, чем линейные классификаторы. Выше Вы также установили, что линейные классификаторы, обучаемые на  признаках изображений, превосходят линейные классификаторы, обучаемые на \"сырых\" пикселях.\n",
    "\n",
    "Для полноты исследований необходимо обучить нейронную сеть на признаках изображений. Такая сеть  должна дать лучшие результаты: вы должны легко получить точность классификации более 55%  на тестовом множестве; наша лучшая модель обладала  точностью  классификации около 60% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка: Удаление измерения, используемого для учета смещения\n",
    "# Эта ячейка блокнота должна выполняться только один  раз!\n",
    "print(X_train_feats.shape)\n",
    "X_train_feats = X_train_feats[:, :-1]\n",
    "X_val_feats = X_val_feats[:, :-1]\n",
    "X_test_feats = X_test_feats[:, :-1]\n",
    "\n",
    "print(X_train_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcv.classifiers.neural_net import TwoLayerNet\n",
    "\n",
    "results = {}       \n",
    "best_val = -1      # Начальное значение валидационной точности\n",
    "\n",
    "learning_rates = [0.05, 0.1, 0.5]                   \n",
    "regularization_strengths = [1e-3, 5e-3, 1e-2]      \n",
    "\n",
    "input_dim = X_train_feats.shape[1]\n",
    "hidden_dim = 100                    # число нейронов скрытого слоя: подбираем \n",
    "num_classes = 10\n",
    "\n",
    "net = TwoLayerNet(input_dim, hidden_dim, num_classes)\n",
    "best_net = None\n",
    "\n",
    "################################################################################\n",
    "# ЗАДАНИЕ: Обучите 2-х слойную нейросеть на признаках изображений. Выполните   #\n",
    "# кросс-валидацию различных парметров, аналогично предыдущим разделам.         #\n",
    "# Сохраните вашу лучшую модель нейросети в переменной best_net.                #            \n",
    "################################################################################\n",
    "# Ваш код\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        net= TwoLayerNet(input_dim, hidden_dim, num_classes)\n",
    "        stats = net.train(X_train_feats, y_train, X_val_feats, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=lr, learning_rate_decay=0.95,\n",
    "            reg=reg, verbose=True)\n",
    "                \n",
    "        val_accuracy=stats['val_acc_history'][-1] \n",
    "        train_accuracy=stats['train_acc_history'][-1]  \n",
    "    \n",
    "        if val_accuracy>best_val:\n",
    "            best_val=val_accuracy\n",
    "            best_net=net\n",
    "            best_stats=stats\n",
    "        results[(lr,reg)]=(train_accuracy,val_accuracy)\n",
    "        \n",
    "# Печать результатов .\n",
    "for lr, reg in sorted(results):\n",
    "            train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "            print('lr %e reg %e точность обучения: %f валидационная точность: %f' % (\n",
    "                                    lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('Наилучшая валидационная точность полученная в ходе кросс-валидации: %f' % best_val)\n",
    "################################################################################\n",
    "#                              КОНЕЦ ВАШЕГО КОДА                               #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверьте Вашу лучшую модель на тестовом множестве. Вы должы получить\n",
    "# точность классификации примерно 55%\n",
    "\n",
    "test_acc = (best_net.predict(X_test_feats) == y_test).mean()\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
