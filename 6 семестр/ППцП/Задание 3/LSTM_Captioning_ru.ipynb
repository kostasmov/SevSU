{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# LSTM сети\n",
    "В предыдущем упражнении Вы реализовали обычную RNN и применили её для формирования подписей к изображениям. В этом блокноте Вы реализуете правило обучения LSTM сети и примените  её для формирования подписей к изображениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Необходимые установки\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dlcv.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from dlcv.rnn_layers import *\n",
    "from dlcv.captioning_solver import CaptioningSolver\n",
    "from dlcv.classifiers.rnn import CaptioningRNN\n",
    "from dlcv.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from dlcv.image_utils import image_from_url\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# для авто перезагрузки внешних модулей \n",
    "# см. http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" возвращает относительную ощибку \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных  MS-COCO\n",
    "\n",
    "Как и в предыдущем блокноте, будем использовать набор данных Microsoft COCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных COCO c диска; функция возвращает словарь\n",
    "# В этом блокноте будем работать с сокращенной размерностью признаков \n",
    "# Вы можете использовать исходные признаковые данные (fc7), изменив флаг ниже\n",
    "\n",
    "data = load_coco_data(pca_features=True)\n",
    "\n",
    "# Печать названий ключей и типов значений из словаря данных\n",
    "for k, v in data.items():\n",
    "    if type(v) == np.ndarray:\n",
    "        print(k, type(v), v.shape, v.dtype)\n",
    "    else:\n",
    "        print(k, type(v), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "Если вы прочтете последние статьи в области DL, то увидите, что во многих случаях используется вариант RNN, называемый RNN с долгой кратковременной памятью (LSTM - Long-Short Term Memory). Обычные RNN могут плохо обучаться на длинных последовательностях из-за исчезновения или роста градиентов, вызванного многократным умножением на матрицу весов. LSTM решают эту проблему, заменяя простое правило обучения обычной RNN некоторым вентильным механизмом (gating mechanism).\n",
    "\n",
    "\n",
    "Как и в обычной RNN, на каждом временном шаге мы получаем вход  $x_t\\in\\mathbb{R}^D$ и предыдущее скрытое состояние $h_{t-1}\\in\\mathbb{R}^H$; LSTM также поддерживает дополнительно так называемое $H$-мерное *состояние ячейки*, для которого мы также получаем предыдущее состояние ячейки $c_{t-1}\\in\\mathbb{R}^H$. Обучаемыми параметрами LSTM являются *input-to-hidden*  матрица  $W_x\\in\\mathbb{R}^{4H\\times D}$, *hidden-to-hidden* матрица   $W_h\\in\\mathbb{R}^{4H\\times H}$ и *вектор смещения* $b\\in\\mathbb{R}^{4H}$ .\n",
    "\n",
    "\n",
    "На каждом временном шаге мы сначала вычисляем *вектор активации* $a\\in\\mathbb{R}^{4H}$ как $a=W_xx_t + W_hh_{t-1}+b$. Затем мы делим его на четыре вектора: $a_i,a_f,a_o,a_g\\in\\mathbb{R}^H$, где $a_i$ состоит из первых  $H$ элементов $a$, $a_f$ следующие $H$ элементов $a$ и т.д. Затем вычисляем векторы: (*input gate*) $g\\in\\mathbb{R}^H$, (*forget gate*) $f\\in\\mathbb{R}^H$, (*output gate*) $o\\in\\mathbb{R}^H$ и (*block input*) $g\\in\\mathbb{R}^H$ как\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "i = \\sigma(a_i) \\hspace{2pc}\n",
    "f = \\sigma(a_f) \\hspace{2pc}\n",
    "o = \\sigma(a_o) \\hspace{2pc}\n",
    "g = \\tanh(a_g)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "где $\\sigma$  - сигмоидная функция и  $\\tanh$ - функция гиперболического тангенса, применяемые поэлементно.\n",
    "\n",
    "Затем вычисляются следующее состояние ячейки $c_t$ и следующее скрытое состояние $h_t$ как\n",
    "\n",
    "$$\n",
    "c_{t} = f\\odot c_{t-1} + i\\odot g \\hspace{4pc}\n",
    "h_t = o\\odot\\tanh(c_t)\n",
    "$$\n",
    "\n",
    "где $\\odot$ поэлементное произведение векторов. \n",
    "\n",
    "Далее  мы реализуем правило обучения LSTM и применим его для формирования подписей к изображениям.\n",
    "\n",
    "При кодировании предполагается, что данные хранятся в блоках так, что\n",
    "$X_t \\in \\mathbb{R}^{N\\times D}$, и мы используем *транспонированную* версию параметров: $W_x \\in \\mathbb{R}^{D \\times 4H}$, $W_h \\in \\mathbb{R}^{H\\times 4H}$ , поэтому активации $A \\in \\mathbb{R}^{N\\times 4H}$ могут вычисляться эффективно как  $A = X_t W_x + H_{t-1} W_h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: шаг прямого распространения\n",
    "Реализуйте прямое распространение для одного временного шага LSTM в функции `lstm_step_forward` в файле` dlcv / rnn_layers.py`. Это  похоже на функцию `rnn_step_forward`, которую вы реализовали выше, но вместо этого необходимо использовать схему ячейки LSTM.\n",
    "\n",
    "Затем протестируйте вашу реализацию. Ошибки должны быть на уровне «e-8» или менее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, H = 3, 4, 5\n",
    "x = np.linspace(-0.4, 1.2, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.3, 0.7, num=N*H).reshape(N, H)\n",
    "prev_c = np.linspace(-0.4, 0.9, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-2.1, 1.3, num=4*D*H).reshape(D, 4 * H)\n",
    "Wh = np.linspace(-0.7, 2.2, num=4*H*H).reshape(H, 4 * H)\n",
    "b = np.linspace(0.3, 0.7, num=4*H)\n",
    "\n",
    "next_h, next_c, cache = lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)\n",
    "\n",
    "expected_next_h = np.asarray([\n",
    "    [ 0.24635157,  0.28610883,  0.32240467,  0.35525807,  0.38474904],\n",
    "    [ 0.49223563,  0.55611431,  0.61507696,  0.66844003,  0.7159181 ],\n",
    "    [ 0.56735664,  0.66310127,  0.74419266,  0.80889665,  0.858299  ]])\n",
    "expected_next_c = np.asarray([\n",
    "    [ 0.32986176,  0.39145139,  0.451556,    0.51014116,  0.56717407],\n",
    "    [ 0.66382255,  0.76674007,  0.87195994,  0.97902709,  1.08751345],\n",
    "    [ 0.74192008,  0.90592151,  1.07717006,  1.25120233,  1.42395676]])\n",
    "\n",
    "print('Ошибка next_h: ', rel_error(expected_next_h, next_h))\n",
    "print('Ощибка next_c: ', rel_error(expected_next_c, next_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: шаг обратного распространения\n",
    "Реализуйте обратное распространение для одного временного шага LSTM в функции `lstm_step_backward` в файле` dlcv / rnn_layers.py`. Если функция уже реализована, то ознакомьтесь с её реализацией. Затем  выполните числовую проверку градиента  реализации. Ошибки должны быть на уровне «e-7» или менее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "N, D, H = 4, 5, 6\n",
    "x = np.random.randn(N, D)\n",
    "prev_h = np.random.randn(N, H)\n",
    "prev_c = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, 4 * H)\n",
    "Wh = np.random.randn(H, 4 * H)\n",
    "b = np.random.randn(4 * H)\n",
    "\n",
    "next_h, next_c, cache = lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)\n",
    "\n",
    "dnext_h = np.random.randn(*next_h.shape)\n",
    "dnext_c = np.random.randn(*next_c.shape)\n",
    "\n",
    "fx_h = lambda x: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fh_h = lambda h: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fc_h = lambda c: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fWx_h = lambda Wx: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fWh_h = lambda Wh: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fb_h = lambda b: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "\n",
    "fx_c = lambda x: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fh_c = lambda h: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fc_c = lambda c: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fWx_c = lambda Wx: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fWh_c = lambda Wh: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fb_c = lambda b: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "\n",
    "num_grad = eval_numerical_gradient_array\n",
    "\n",
    "dx_num = num_grad(fx_h, x, dnext_h) + num_grad(fx_c, x, dnext_c)\n",
    "dh_num = num_grad(fh_h, prev_h, dnext_h) + num_grad(fh_c, prev_h, dnext_c)\n",
    "dc_num = num_grad(fc_h, prev_c, dnext_h) + num_grad(fc_c, prev_c, dnext_c)\n",
    "dWx_num = num_grad(fWx_h, Wx, dnext_h) + num_grad(fWx_c, Wx, dnext_c)\n",
    "dWh_num = num_grad(fWh_h, Wh, dnext_h) + num_grad(fWh_c, Wh, dnext_c)\n",
    "db_num = num_grad(fb_h, b, dnext_h) + num_grad(fb_c, b, dnext_c)\n",
    "\n",
    "dx, dh, dc, dWx, dWh, db = lstm_step_backward(dnext_h, dnext_c, cache)\n",
    "\n",
    "print('Ошибка dx: ', rel_error(dx_num, dx))\n",
    "print('Ошибка dh: ', rel_error(dh_num, dh))\n",
    "print('Ошибка dc: ', rel_error(dc_num, dc))\n",
    "print('Ошибка dWx: ', rel_error(dWx_num, dWx))\n",
    "print('Ошибка dWh: ', rel_error(dWh_num, dWh))\n",
    "print('Ошибка db: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: прямое распространение\n",
    "В функции `lstm_forward` в файле` dlcv / rnn_layers.py` реализуйте функцию `lstm_forward` , которая  выполняет прямое распространение, используя весь временной ряд данных.\n",
    "\n",
    "Затем проверьте реализацию. Ошибка дожна быть на уровне «e-7» или менее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, H, T = 2, 5, 4, 3\n",
    "x = np.linspace(-0.4, 0.6, num=N*T*D).reshape(N, T, D)\n",
    "h0 = np.linspace(-0.4, 0.8, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.2, 0.9, num=4*D*H).reshape(D, 4 * H)\n",
    "Wh = np.linspace(-0.3, 0.6, num=4*H*H).reshape(H, 4 * H)\n",
    "b = np.linspace(0.2, 0.7, num=4*H)\n",
    "\n",
    "h, cache = lstm_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "expected_h = np.asarray([\n",
    " [[ 0.01764008,  0.01823233,  0.01882671,  0.0194232 ],\n",
    "  [ 0.11287491,  0.12146228,  0.13018446,  0.13902939],\n",
    "  [ 0.31358768,  0.33338627,  0.35304453,  0.37250975]],\n",
    " [[ 0.45767879,  0.4761092,   0.4936887,   0.51041945],\n",
    "  [ 0.6704845,   0.69350089,  0.71486014,  0.7346449 ],\n",
    "  [ 0.81733511,  0.83677871,  0.85403753,  0.86935314]]])\n",
    "\n",
    "print('Ошибка h: ', rel_error(expected_h, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: обратное распространение\n",
    "Реализуйте обратное распространение для LSTM по всей временной последовательности данных в функции `lstm_backward` в файле` dlcv / rnn_layers.py`. Если функция уже реализована, то ознакомьтесь с её реализацией. Затем  выполните  числовую проверку градиента. Ошибки должны быть на уровне «e-8» или менее. (Для `dWh` хорошо, если ваша примерно `e-6` или меньше)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcv.rnn_layers import lstm_forward, lstm_backward\n",
    "np.random.seed(231)\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 6\n",
    "\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, 4 * H)\n",
    "Wh = np.random.randn(H, 4 * H)\n",
    "b = np.random.randn(4 * H)\n",
    "\n",
    "out, cache = lstm_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "dout = np.random.randn(*out.shape)\n",
    "\n",
    "dx, dh0, dWx, dWh, db = lstm_backward(dout, cache)\n",
    "\n",
    "fx = lambda x: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "fh0 = lambda h0: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "fb = lambda b: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dh0_num = eval_numerical_gradient_array(fh0, h0, dout)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dout)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "\n",
    "print('Ошибка dx: ', rel_error(dx_num, dx))\n",
    "print('Ошибка dh0: ', rel_error(dh0_num, dh0))\n",
    "print('Ошибка dWx: ', rel_error(dWx_num, dWx))\n",
    "print('Ошибка dWh: ', rel_error(dWh_num, dWh))\n",
    "print('Ошибка db: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "# ВОПРОС\n",
    "\n",
    "Напомним, что в LSTM input gate $i$, forget gate $f$ и output gate $o$ являются выходами сигмоидной функции. Почему мы не используем функцию активации ReLU вместо сигмоидной для вычисления этих значений? Объясните.\n",
    "\n",
    "**Ваш ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM модель формирования подписей\n",
    "\n",
    "Теперь, когда вы реализовали LSTM, обновите реализацию метода `loss` класса` CaptioningRNN` в файле `dlcv / classifiers / rnn.py`, чтобы обработать случай, когда` self.cell_type` равен `lstm`. Это  потребует добавления менее 10 строк кода.Если в файле код уже реализован, то просто ознакомьтесь с ним.\n",
    "\n",
    "Проверьте реализацию. Разность должна быть на уровне `e-10` или менее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, W, H = 10, 20, 30, 40\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "V = len(word_to_idx)\n",
    "T = 13\n",
    "\n",
    "model = CaptioningRNN(word_to_idx,\n",
    "          input_dim=D,\n",
    "          wordvec_dim=W,\n",
    "          hidden_dim=H,\n",
    "          cell_type='lstm',\n",
    "          dtype=np.float64)\n",
    "\n",
    "# Установка всех параметров модели в виде фиксированных значений\n",
    "for k, v in model.params.items():\n",
    "  model.params[k] = np.linspace(-1.4, 1.3, num=v.size).reshape(*v.shape)\n",
    "\n",
    "features = np.linspace(-0.5, 1.7, num=N*D).reshape(N, D)\n",
    "captions = (np.arange(N * T) % V).reshape(N, T)\n",
    "\n",
    "loss, grads = model.loss(features, captions)\n",
    "expected_loss = 9.82445935443\n",
    "\n",
    "print('Потери: ', loss)\n",
    "print('Ожидаемые потери: ', expected_loss)\n",
    "print('Разность: ', abs(loss - expected_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение LSTM модели для формирования подписей к изображениям\n",
    "\n",
    "Выполните ячейку ниже, чтобы обучить модель LSTM, формирующую подписи к изображениям, на  том же небольшом наборе данных, который мы использовали ранее для RNN . Вы должны увидеть окончательные потери менее 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "small_data = load_coco_data(max_train=50)\n",
    "\n",
    "small_lstm_model = CaptioningRNN(\n",
    "          cell_type='lstm',\n",
    "          word_to_idx=data['word_to_idx'],\n",
    "          input_dim=data['train_features'].shape[1],\n",
    "          hidden_dim=512,\n",
    "          wordvec_dim=256,\n",
    "          dtype=np.float32,\n",
    "        )\n",
    "\n",
    "small_lstm_solver = CaptioningSolver(small_lstm_model, small_data,\n",
    "           update_rule='adam',\n",
    "           num_epochs=50,\n",
    "           batch_size=25,\n",
    "           optim_config={\n",
    "             'learning_rate': 5e-3,\n",
    "           },\n",
    "           lr_decay=0.995,\n",
    "           verbose=True, print_every=10,\n",
    "         )\n",
    "\n",
    "small_lstm_solver.train()\n",
    "\n",
    "# Plot the training losses\n",
    "plt.plot(small_lstm_solver.loss_history)\n",
    "plt.xlabel('Итерации')\n",
    "plt.ylabel('Потери')\n",
    "plt.title('История потерь обучения')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: результаты тестирования\n",
    "Измените метод `sample` класса` CaptioningRNN` для обработки случая, когда `self.cell_type` равен` lstm`. Это должно потребовать менее 10 строк кода. Если в файле код уже реализован, то просто ознакомьтесь с ним.\n",
    "\n",
    "После выполните действия в ячейке блокнота ниже, чтобы получить результаты для некоторых примеров тренировочного и проверочного наборов. Как и в случае с RNN, результаты обучения должны быть очень хорошими, а результаты валидации, вероятно, не будут иметь большого смысла (потому что происходит переобучение)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'val']:\n",
    "    minibatch = sample_coco_minibatch(small_data, split=split, batch_size=2)\n",
    "    gt_captions, features, urls = minibatch\n",
    "    gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "    sample_captions = small_lstm_model.sample(features)\n",
    "    sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "    for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "        plt.imshow(image_from_url(url))\n",
    "        plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 4,
           "op": "addrange",
           "valuelist": "7"
          },
          {
           "key": 4,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
