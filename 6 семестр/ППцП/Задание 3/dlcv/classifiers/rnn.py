from builtins import range
from builtins import object
import numpy as np

from dlcv.layers import *
from dlcv.rnn_layers import *


class CaptioningRNN(object):
    """
    Класс создает подписи к изображениям  с помощью RNN.
    Работает с мини-пакетами   размера N. Не использует    регуляризацию.
    """

    def __init__(self, word_to_idx, input_dim=512, wordvec_dim=128,
                 hidden_dim=128, cell_type='rnn', dtype=np.float32):
        """
        Конструктор класса CaptioningRNN.
        Входы:
        - word_to_idx: словарь, содержащий V записей
          и отображающий каждое слово в целое число в диапазоне (0, V).
        - input_dim: размерность вектора признаков  входного изображения, D 
        - wordvec_dim: размерность вектора слов, W
        - hidden_dim: размерность скрытого состояния RNN, H
        - cell_type: либо 'RNN' либо 'LSTM'.
        - dtype: тип данных numpy; float32 для обучения и float64 для
          численной проверки градиента.
        """
        if cell_type not in {'rnn', 'lstm'}:
            raise ValueError('Ошибочное имя ячейки "%s"' % cell_type)

        self.cell_type = cell_type
        self.dtype = dtype
        self.word_to_idx = word_to_idx
        self.idx_to_word = {i: w for w, i in word_to_idx.items()}
        self.params = {}

        vocab_size = len(word_to_idx)

        self._null = word_to_idx['<NULL>']
        self._start = word_to_idx.get('<START>', None)
        self._end = word_to_idx.get('<END>', None)

        #Инициализация и включение в словарь-параметров матрицы векторов слов
        self.params['W_embed'] = np.random.randn(vocab_size, wordvec_dim)
        self.params['W_embed'] /= 100

        #Инициализация матрицы проекции изображений на скрытое состояние
        self.params['W_proj'] = np.random.randn(input_dim, hidden_dim)
        self.params['W_proj'] /= np.sqrt(input_dim)
        self.params['b_proj'] = np.zeros(hidden_dim)

        # Инициализация параметров RNN
        dim_mul = {'lstm': 4, 'rnn': 1}[cell_type]
        self.params['Wx'] = np.random.randn(wordvec_dim, dim_mul * hidden_dim)
        self.params['Wx'] /= np.sqrt(wordvec_dim)
        self.params['Wh'] = np.random.randn(hidden_dim, dim_mul * hidden_dim)
        self.params['Wh'] /= np.sqrt(hidden_dim)
        self.params['b'] = np.zeros(dim_mul * hidden_dim)

        # Инициализация весов и смещений для выходного слоя,
        # преобразующего скр_состояния в рейтинги слов
        self.params['W_vocab'] = np.random.randn(hidden_dim, vocab_size)
        self.params['W_vocab'] /= np.sqrt(hidden_dim)
        self.params['b_vocab'] = np.zeros(vocab_size)

        # Корректировка типа параметров
        for k, v in self.params.items():
            self.params[k] = v.astype(self.dtype)


    def loss(self, features, captions):
        """
        Вычисляет потери по всем параметрам RNN во время обучения. На вход 
        подаются  признаки изображений  и  заголовки для этих изображений.
        Входы:
        - features: Признаки изображении, форма (N, D)
        - captions: Правильные заголовки; целочисленный массив формы (N, T),
        где значение каждого элемента лежит в диапазоне 0 <= y[i, t] < V
        Возвращает кортеж из:
        - loss: Скалярные потери
        - grads: Словарь градиентов, параллельно к self.params
        """
        # Создаем два массива заголовков: captions_in содержит все слова, кроме 
        # последнего слова, и этот массив подается на вход RNN; captions_out 
        # содержит все слова, кроме первого слова, и это то, что мы ожидаем получить на 
        # выходе RNN. Эти два вида заголовков смещены на один элемент относительно 
        # друг друга, RNN должна генерировать слово (t + 1) после получения слова t. 
        # Первым элементом captions_in будет метка START, а первым элементом 
        # captions_out будет первое слово.

        captions_in = captions[:, :-1]
        captions_out = captions[:, 1:]

        # Маска из позиций, где нет null
        mask = (captions_out != self._null)
        
        # Веса и смещения аффинного слоя для преобразования признаков 
        # изображений в начальное скрытое состояние
        W_proj, b_proj = self.params['W_proj'], self.params['b_proj']

        # Матрица векторов слов
        W_embed = self.params['W_embed']

        # Матрицы вх-скр_сост, скр_сост-скр_сост, и смещение для RNN
        Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b']

        # Веса и смещения для слоя преобразования скр_сост-рейтинг_слова
        W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab']

        loss, grads = 0.0, {}
        ############################################################################
        # ЗАДАНИЕ:                                                                 #
        # Реализуйте прямое и обратное распространение для CaptioningRNN.          #
        # При прямом распростарнении Вам нужно будет сделать следующее:            # 
        # (1) Использовать аффинное преобразование для вычисления начального       # 
        # скрытого состояния по входным признакам изображения. В результате будет  #
        # создан массив формы (N, H).                                              #
        # (2) Используйте слой для встраивания слов, чтобы преобразовать слова     #
        # в captions_in из  индексов в векторы, слой создает массив формы (N,T,W). #
        # (3) Используйте обычную RNN или LSTM (в зависимости от self.cell_type)   #   
        # для обработки  последовательности векторов входных слов и формирования   #
        # векторов скрытых состояний для всех временных шагов,сеть формирует       #
        # массив формы (N, T, H).                                                  #
        #(4) Используйте (временное) аффинное преобразование для вычисления        # 
        # рейтингов слов на каждом временном шаге, используя скрытые состояния и   #
        # формируя массив  формы (N, T, V).                                        #
        # (5) Примените функцию softmax для расчета потерь, используя captions_out #
        # и игнорируя точки, где выходное слово равно <NULL>, воспользовавшись     #
        # маской, сфомированной  выше.                                             #
        # При  обратном распространении Вам нужно будет вычислить градиенты потерь #
        # относительно всех параметров модели. Используйте переменные loss и grads,#
        # определенные выше для хранения потерь и градиентов; grads[k] должны      #
        # обеспечивать значениями градиентов self.params [k].                      #
        ############################################################################
        # *****НАЧАЛО ВАШЕГО КОДА (НЕ УДАЛЯЙТЕ/НЕ МОДИФИЦИРУЙТЕ ЭТУ СТРОКУ)*****
        
        # Прямое распространение 
       
       # 1. Получаем, h0 преобразуя изображение c  помощью аффинного слоя
        h0,cache1 = affine_forward(features, W_proj, b_proj)  #[NxH]
       
        # 2. Получаем последовательность векторов слов из вх. заголовка
        x,cache2 = word_embedding_forward(captions_in, W_embed) #[NxTxW]
        
        # 3. Прямая обработка вх. последовательности для всех шагов по времени
        if self.cell_type == 'rnn':
            h,cache3 = rnn_forward(x, h0, Wx, Wh, b) #[NxTxH]
        else:
            h,cache3 = lstm_forward(x, h0, Wx, Wh, b) #[NxTxH]
        
        #4. Вычисление рейтингов слов с использов. временного аффинного слоя
        score,cache4 = temporal_affine_forward(h, W_vocab, b_vocab) #[NxTxV]
       
        #5. Вычисление потерь и градиентов
        loss,dscore = temporal_softmax_loss(score, captions_out, mask, verbose=False)

        # Обратное распространение
        # Вычисление градиентов по всем параметрам
      
        #1. Временной аффинный слой
        dh, dW_vocab, db_vocab = temporal_affine_backward(dscore, cache4)
        #2. RNN
        if self.cell_type == 'rnn':
           dx, dh0, dWx, dWh, db = rnn_backward(dh, cache3)
        else:
           dx, dh0, dWx, dWh, db = lstm_backward(dh, cache3)
        #3. Слой встраивания слов
        dW_embed = word_embedding_backward(dx, cache2)
        #4. Слой проецирования признаков изображения на h0
        dW_proj = features.T.dot(dh0)
        db_proj = dh0.sum(axis=0)
        #5. Формирование словаря градиентов по всем параметрам
        grads = {'W_vocab':dW_vocab, 'b_vocab':db_vocab, 'Wx':dWx, 'Wh':dWh,'b':db, 'W_embed':dW_embed, 'W_proj':dW_proj, 'b_proj':db_proj}

        pass

        # *****КОНЕЦ ВАШЕГО КОДА (НЕ УДАЛЯЙТЕ/НЕ МОДИФИЦИРУЙТЕ ЭТУ СТРОКУ)*****
        ##############################################################################
        #                               Конец Вашего кода                            #
        ##############################################################################

        return loss, grads


    def sample(self, features, max_length=30):
        """
          Выполняет  прямое распространение на этапе тестирования для модели, выполняющей формирование 
          подписей  к  изображениям.
          
          На каждом временном шаге формируется вектор текущего слова и передается
          вместе с предыдущим cкрытым  состоянием  на вход RNN для получения  
          следующего скрытого состояния, новое скрытое состояние используется 
          для получения рейтингов  всех слов, далее выбирается слово с наибольшим
          рейтингом в качестве следующего слова. Начальное скрытое состояние 
          вычисляется путем применения аффинного  преобразования входного изображения, 
          а начальное слово  --  это токен  <START>.
          
          Для LSTM также отслеживаееся состояние ячейки; в этом случае   начальное
          состояние ячейки должно быть нулевым.
          Входы:
          - features: Массив входных признаков изображений, (N, D).
          - max_length: максимальная длина сгенерированных заголовков, T
          Возвращает:
          - captions: массив  заголовков формы (N, max_length),  где каждый  
          элемент является целым числом в диапазоне [0, V). Первый элемент 
          заголовка должен быть первым выбранным словом, а не токеном <START>.
        """
        N = features.shape[0]
        captions = self._null * np.ones((N, max_length), dtype=np.int32)

        # Извлечение параметров
        W_proj, b_proj = self.params['W_proj'], self.params['b_proj']
        W_embed = self.params['W_embed']
        Wx, Wh, b = self.params['Wx'], self.params['Wh'], self.params['b']
        W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab']

        ###########################################################################
        # ЗАДАНИЕ: Реализовать тестирование модели. Вам нужно будет               #
        # инициализировать скрытое состояние RNN, применяя  аффинный слой         #
        # для преобразования входного изображения. Первое слово, которое Вы       #
        # подаете  на вход  RNN должно быть токеном <START>; его значение         #
        # хранится в переменной self._start.                                      #
        # На каждом временном шаге вам нужно будет сделать следующее:             #
        # (1) Встроить предыдущее слово, используя обученные вектора слов.        #
        # (2) Сделать шаг RNN, используя  скрытое состояние и встроенное          #
        # текущее слово, чтобы получить следующее скрытое состояние.              #
        # (3) Применить обученное аффинное преобразование к следующему            #
        #  скрытому состоянию, чтобы получить рейтиги всех слов словаря.          #
        # (4) Выбрать слово с наибольшим рейтингом в качестве следующего слова,   #
        # записать его (индекс слова) в соответствующую позицию переменной        #
        # captions.                                                               #
        # С целью упрощения Вам не нужно будет останавливать генерацию после      #
        # токена <END>, но Вы можете это сделать, если хотите.                    #
        #                                                                         #
        # СОВЕТ: Вы не сможете использовать функции rnn_forward или lstm_forward; #
        # Вам нужно вызывать  rnn_step_forward или lstm_step_forward в цикле.     #
        #                                                                         #
        # ПРИМЕЧАНИЕ: Мы все еще работаем в этой функции с мини-пакетами. Также   #
        # если Вы используете LSTM, инициализируйте первое состояние  нулями.     #
        ###########################################################################
        # *****НАЧАЛО ВАШЕГО КОДА (НЕ УДАЛЯЙТЕ/НЕ МОДИФИЦИРУЙТЕ ЭТУ СТРОКУ)*****
        
        # Формируем целочисленные коды начальных слов
        index = self._start * np.ones((N), dtype=np.int32)  #(N,)
        # Вычисляем значение  скрытого состояния h0  
        h_next, _ = affine_forward(features, W_proj, b_proj)   #(N,H)
        prev_c = np.zeros_like(h_next)     # только LSTM
         #  Выполняем циклически прямую  передачу через ячейку RNN
        for i in range(max_length):
            # Формируем векторы слов по их целочисленным кодам
            word_v, _ = word_embedding_forward(index, W_embed)   # (N,W)
            # Вычисляем новое значение скрытого состояния
            if self.cell_type == 'rnn':
                h_next, _ = rnn_step_forward(word_v, h_next, Wx, Wh, b)
            else:
                h_next, prev_c, _ = lstm_step_forward(word_v, h_next, prev_c, Wx, Wh, b)
            # Вычисляем рейтинги слов и находим максимальный для всех N
            pred, _ = affine_forward(h_next, W_vocab, b_vocab)  #(N,V)
            index = np.argmax(pred, axis=-1)  # (N,)
            # Размещаем индексы слов с макс рейтингом в i-oй позиции заголовков
            captions[:, i] = index

        pass

        # *****КОНЕЦ ВАШЕГО КОДА (НЕ УДАЛЯЙТЕ/НЕ МОДИФИЦИРУЙТЕ ЭТУ СТРОКУ)*****
        ############################################################################
        #                               Конец Вашего кода                          #
        ############################################################################
        return captions
